{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8621def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "import sys\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "class Candidate(str):\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        super().__init__()\n",
    "        self.start = 0\n",
    "        self.stop = 0\n",
    "\n",
    "    def set_position(self, start, stop):\n",
    "        self.start = start\n",
    "        self.stop = stop\n",
    "\n",
    "class ExtractAcronymDefinitionPair:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def _yield_lines_from_file(self,file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    line = line.decode('utf-8')\n",
    "                except UnicodeDecodeError:\n",
    "                    line = line.decode('latin-1').encode('utf-8').decode('utf-8')\n",
    "                line = line.strip()\n",
    "                yield line\n",
    "\n",
    "    def _yield_lines_from_doc(self,doc_text):\n",
    "        for line in doc_text.split(\"\\n\"):\n",
    "            yield line.strip()\n",
    "\n",
    "    def _best_candidates(self,sent):\n",
    "\n",
    "        if '(' in sent:\n",
    "            # Check some things first\n",
    "            if sent.count('(') != sent.count(')'):\n",
    "                raise ValueError(\"Unbalanced parentheses: {}\".format(sent))\n",
    "\n",
    "            if sent.find('(') > sent.find(')'):\n",
    "                raise ValueError(\"First parentheses is right: {}\".format(sent))\n",
    "\n",
    "            close_index = -1\n",
    "            while 1:\n",
    "                open_index = sent.find(' (', close_index + 1)\n",
    "                if open_index == -1: break\n",
    "                open_index += 1\n",
    "                close_index = open_index + 1\n",
    "                open_count = 1\n",
    "                skip = False\n",
    "                while open_count:\n",
    "                    try:\n",
    "                        char = sent[close_index]\n",
    "                    except IndexError:\n",
    "                        skip = True\n",
    "                        break\n",
    "                    if char == '(':\n",
    "                        open_count += 1\n",
    "                    elif char in [')', ';', ':']:\n",
    "                        open_count -= 1\n",
    "                    close_index += 1\n",
    "\n",
    "                if skip:\n",
    "                    close_index = open_index + 1\n",
    "                    continue\n",
    "\n",
    "                start = open_index + 1\n",
    "                stop = close_index - 1\n",
    "                candidate = sent[start:stop]\n",
    "\n",
    "                start = start + len(candidate) - len(candidate.lstrip())\n",
    "                stop = stop - len(candidate) + len(candidate.rstrip())\n",
    "                candidate = sent[start:stop]\n",
    "\n",
    "                if self._conditions(candidate):\n",
    "                    new_candidate = Candidate(candidate)\n",
    "                    new_candidate.set_position(start, stop)\n",
    "                    yield new_candidate\n",
    "\n",
    "    def _conditions(self,candidate):\n",
    "\n",
    "        viable = True\n",
    "        if regex.match(r'(\\p{L}\\.?\\s?){2,}', candidate.lstrip()):\n",
    "            viable = True\n",
    "        if len(candidate) < 2 or len(candidate) > 10:\n",
    "            viable = False\n",
    "        if len(candidate.split()) > 2:\n",
    "            viable = False\n",
    "        if not regex.search(r'\\p{L}', candidate):\n",
    "            viable = False\n",
    "        if not candidate[0].isalnum():\n",
    "            viable = False\n",
    "\n",
    "        return viable\n",
    "\n",
    "    def _get_definition(self,candidate, sent):\n",
    "\n",
    "        tokens = regex.split(r'[\\s\\-]+', sent[:candidate.start - 2].lower())\n",
    "        key = candidate[0].lower()\n",
    "        first_chars = [t[0] for t in filter(None, tokens)]\n",
    "        definition_freq = first_chars.count(key)\n",
    "        candidate_freq = candidate.lower().count(key)\n",
    "\n",
    "        if candidate_freq <= definition_freq:\n",
    "            count = 0\n",
    "            start = 0\n",
    "            start_index = len(first_chars) - 1\n",
    "            while count < candidate_freq:\n",
    "                if abs(start) > len(first_chars):\n",
    "                    raise ValueError(\"candidate {} not found\".format(candidate))\n",
    "                start -= 1\n",
    "                try:\n",
    "                    start_index = first_chars.index(key, len(first_chars) + start)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "                count = first_chars[start_index:].count(key)\n",
    "\n",
    "            start = len(' '.join(tokens[:start_index]))\n",
    "            stop = candidate.start - 1\n",
    "            candidate = sent[start:stop]\n",
    "\n",
    "            start = start + len(candidate) - len(candidate.lstrip())\n",
    "            stop = stop - len(candidate) + len(candidate.rstrip())\n",
    "            candidate = sent[start:stop]\n",
    "            new_candidate = Candidate(candidate)\n",
    "            new_candidate.set_position(start, stop)\n",
    "            return new_candidate\n",
    "\n",
    "        else:\n",
    "            raise ValueError('There are less keys in the tokens in front of candidate than there are in the candidate')\n",
    "\n",
    "    def _select_definition(self,definition, abbrev):\n",
    "\n",
    "        if len(definition) < len(abbrev):\n",
    "            raise ValueError('Abbreviation is longer than definition')\n",
    "\n",
    "        if abbrev in definition.split():\n",
    "            raise ValueError('Abbreviation is full word of definition')\n",
    "\n",
    "        s_index = -1\n",
    "        l_index = -1\n",
    "\n",
    "        while 1:\n",
    "            try:\n",
    "                long_char = definition[l_index].lower()\n",
    "            except IndexError:\n",
    "                raise\n",
    "\n",
    "            short_char = abbrev[s_index].lower()\n",
    "\n",
    "            if not short_char.isalnum():\n",
    "                s_index -= 1\n",
    "\n",
    "            if s_index == -1 * len(abbrev):\n",
    "                if short_char == long_char:\n",
    "                    if l_index == -1 * len(definition) or not definition[l_index - 1].isalnum():\n",
    "                        break\n",
    "                    else:\n",
    "                        l_index -= 1\n",
    "                else:\n",
    "                    l_index -= 1\n",
    "                    if l_index == -1 * (len(definition) + 1):\n",
    "                        raise ValueError(\"definition {} was not found in {}\".format(abbrev, definition))\n",
    "\n",
    "            else:\n",
    "                if short_char == long_char:\n",
    "                    s_index -= 1\n",
    "                    l_index -= 1\n",
    "                else:\n",
    "                    l_index -= 1\n",
    "\n",
    "        new_candidate = Candidate(definition[l_index:len(definition)])\n",
    "        new_candidate.set_position(definition.start, definition.stop)\n",
    "        definition = new_candidate\n",
    "\n",
    "        tokens = len(definition.split())\n",
    "        length = len(abbrev)\n",
    "\n",
    "        if tokens > min([length + 5, length * 2]):\n",
    "            raise ValueError(\"did not meet min(|A|+5, |A|*2) constraint\")\n",
    "\n",
    "        if definition.count('(') != definition.count(')'):\n",
    "            raise ValueError(\"Unbalanced parentheses not allowed in a definition\")\n",
    "\n",
    "        return definition\n",
    "\n",
    "    def extract(self,file_path=None,doc_text=None,most_common_definition=False,first_definition=False):\n",
    "        abbrev_map = dict()\n",
    "        list_abbrev_map = defaultdict(list)\n",
    "        counter_abbrev_map = dict()\n",
    "        omit = 0\n",
    "        written = 0\n",
    "        if file_path:\n",
    "            sentence_iterator = enumerate(self._yield_lines_from_file(file_path))\n",
    "        elif doc_text:\n",
    "            sentence_iterator = enumerate(self._yield_lines_from_doc(doc_text))\n",
    "        else:\n",
    "            return abbrev_map\n",
    "\n",
    "        \n",
    "        collect_definitions = True if most_common_definition or first_definition else False\n",
    "\n",
    "        for i, sentence in sentence_iterator:\n",
    "            clean_sentence = regex.sub(r'([(])[\\'\"\\p{Pi}]|[\\'\"\\p{Pf}]([);:])', r'\\1\\2', sentence)\n",
    "            try:\n",
    "                for candidate in self._best_candidates(clean_sentence):\n",
    "                    try:\n",
    "                        definition = self._get_definition(candidate, clean_sentence)\n",
    "                    except (ValueError, IndexError) as e:\n",
    "                        print(f\"{i} Omitting candidate {candidate}. Reason: {e.args[0]}\")\n",
    "                        omit += 1\n",
    "                    else:\n",
    "                        try:\n",
    "                            definition = self._select_definition(definition, candidate)\n",
    "                        except (ValueError, IndexError) as e:\n",
    "                            print(f\"{i} Omitting definition {definition} for candidate {candidate}. Reason: {e.args[0]}\")\n",
    "                            omit += 1\n",
    "                        else:\n",
    "                            if collect_definitions:\n",
    "                                list_abbrev_map[candidate].append(definition)\n",
    "                            else:\n",
    "                                abbrev_map[candidate] = definition\n",
    "                            written += 1\n",
    "            except (ValueError, IndexError) as e:\n",
    "                print(f\"{i} Error processing sentence {sentence}: {e.args[0]}\")\n",
    "        print(f\"{written} abbreviations detected and kept ({omit} omitted)\")\n",
    "\n",
    "        if collect_definitions:\n",
    "            if most_common_definition:\n",
    "                for k,v in list_abbrev_map.items():\n",
    "                    counter_abbrev_map[k] = Counter(v).most_common(1)[0][0]\n",
    "            else:\n",
    "                for k, v in list_abbrev_map.items():\n",
    "                    counter_abbrev_map[k] = v[0]\n",
    "            return counter_abbrev_map\n",
    "\n",
    "        return abbrev_map\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67909479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 abbreviations detected and kept (0 omitted)\n",
      "{'DU': 'Delhi University', 'B.Sc': 'Bachelor in Science', 'NCR': 'National Capital Region'}\n"
     ]
    }
   ],
   "source": [
    "text =\" I studied in Delhi University (DU) where I studied Bachelor in Science (B.Sc). I live in New Delhi whihc is an National Capital Region (NCR)\"\n",
    "obj = ExtractAcronymDefinitionPair()\n",
    "print(obj.extract(doc_text=text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b661ad4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
